# 네번째 배움
###### 2019.04.15 (월)
##### keras에 대해 공부 중...(4)
###### https://www.tensorflow.org/tutorials/keras
##### Bayesian Deep Learning에 대해 공부 중...(3)
###### Edwith 강의 https://www.edwith.org/bayesiandeeplearning/joinLectures/14426

-----
### (keras) 이모저모
##### *categorical_crossentropy* vs *sparse_categorical_cross_entropy*
  
나의 경우 categorical_crossentropy는 무엇인가라는 질문부터 시작했다. *categorical*이라는 말이 들어감에 따라 무언가 달라지는 줄 알았다.
결론적으로는 내가 원래 알고 있던 crossentropy와 같은 것이었다. keras에서 명명하기를 categorical_crossentropy라고 한 것이었다.
  
그렇다면 *sparse*가 붙는 것은 무엇일까? 본질은 기존 categorical_crossentropy와 같다. 
다만, input data가 vectorize되지 않았을 때 사용하는 것이 sparse_categorical_crossentropy이다.
  
예를 들어 ['apple', 'car', 'universe'] 라는 단어묶음이 있을 때 각 단어를 
[[0, 0, 1], [0, 1, 0], [1, 0, 0]] (one-hot encoding)으로 vectorize한 상태라, categorical_crossentropy를 사용하면 된다.
만약 각 단어를 [1, 2, 3]으로 표현했다면 이때는 sparse_categorical_crossentropy를 사용하면 된다.
