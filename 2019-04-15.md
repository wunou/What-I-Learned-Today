# 네번째 배움
###### 2019.04.15 (월)
##### keras에 대해 공부 중...(4)
###### https://www.tensorflow.org/tutorials/keras
##### Bayesian Deep Learning에 대해 공부 중...(3)
###### Edwith 강의 https://www.edwith.org/bayesiandeeplearning/joinLectures/14426

-----
### (keras) 이모저모
##### *categorical_crossentropy* vs *sparse_categorical_cross_entropy*
  
나의 경우 categorical_crossentropy는 무엇인가라는 질문부터 시작했다. *categorical*이라는 말이 들어감에 따라 무언가 달라지는 줄 알았다.
결론적으로는 내가 원래 알고 있던 crossentropy와 같은 것이었다. keras에서 명명하기를 categorical_crossentropy(y값에 따라 category가 분류된다는 의미로 이렇게 쓴 것 같다.)라고 한 것이었다.
  
그렇다면 *sparse*가 붙는 것은 무엇일까? 본질은 기존 categorical_crossentropy와 같다. 
다만, input data가 vectorize되지 않았을 때 사용하는 것이 sparse_categorical_crossentropy이다. 
예를 들어 \['apple', 'car', 'universe'\] 라는 단어묶음이 있을 때 단어의 표현에 따른 손실함수 사용은 다음과 같다.
  
* \[\[0, 0, 1\], \[0, 1, 0\], \[1, 0, 0\]\] (one-hot encoding) => **categorical_crossentropy**
* \[1, 2, 3\] => **sparse_categorical_crossentropy**
