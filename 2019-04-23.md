# 열번째 배움
###### 2019.04.23 (화)
##### keras에 대해 공부 중
###### https://www.tensorflow.org/tutorials/keras

-------

### (keras) Overfitting and Underfiiting

weight의 개수에 따른 overfitting, underfitting의 val_loss를 비교하여 보았고, 
이를 해결하기 위해 l2 regularizer, dropout을 사용하였다. 
  
```python
# l2 regularizer
l2_model = keras.models.Sequential([
    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),
                       activation=tf.nn.relu, input_shape=(NUM_WORDS,)),
    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),
                       activation=tf.nn.relu),
    keras.layers.Dense(1, activation=tf.nn.sigmoid)
])
```
  
```python
# dropout
dpt_model = keras.models.Sequential([
    keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(NUM_WORDS,)),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(16, activation=tf.nn.relu),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(1, activation=tf.nn.sigmoid)
])
```

<br>
<br>

### 밑바닥부터 시작하는 딥러닝 
##### 1장 ~ 3장

항상 오픈소스 라이브러리 tensorflow, keras, pytorch 등으로만 사용하던 것들에 대한 구현을 연습해보기 위해 
'밑바닥부터 시작하는 딥러닝' 책을 처음부터 보고있다.
현재는 간단한 모델의 feed forward 부분까지 구현해보았다.  
해당 연습 코드들을 (좀 지저분하겠지만..) 깃헙에 올려봐야겠다.  

