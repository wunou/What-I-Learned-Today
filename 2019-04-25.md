# 열번째 배움
###### 2019.04.23 (화)
##### keras에 대해 공부 중
###### https://www.tensorflow.org/tutorials/keras
##### (edwith) Bayesian Deep Learning에 대해 공부 중
###### https://www.edwith.org/bayesiandeeplearning/joinLectures/14426

------
<br>

### (keras) Save and Restore models


<br>
<br>

### (Bayesian Deep Learning) Functional Analysis
##### Define Spaces

공간을 정의한다는 것은 무엇일까? 실수 공간은 어떻게 정의할 수 있을까? 이는 결국 axiom들의 연속이 될 것이다.  
본 강의에서 나온 공간들은 다음과 같다. 순석대로 더 좁은 공간이다.  

* Vector space (addition, scalar multiplication, ...)
* Metric space (distance)
* Normed space (size)
* Inner-product space (similarity)
* Hilbert space (complete space => always possible to fill all the holes.(R is, but Q is not))

Kernel 이란 무엇일까?  
&nbsp; Let *X* be a non-empty set. A function *X*x*X* → *R* is a kernel 
if there exists a Hilbert space *H* and map Φ : *X* → *H* such that ∀x, x'∈*X*, 
k(x, x') ≡ <Φ(x), Φ(x')><sub>*H*<sub>
  
말이 어렵긴 하지만(물론 말만 어려운 건 아닌 거 같다.), 결국 kernel은 매우 loose하게 정의가 되어있다. empty set가 있으면 되고, 
 추가로 이 set에 있는 elements을 inner-product이 정의되어 있는 Hilbert space로 보내는 Φ라는 함수만 있으면 된다.
