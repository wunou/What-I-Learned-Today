# 세번째 배움
###### 2019.04.11 (목)
##### keras에 대해 공부 중...(2)
###### https://www.tensorflow.org/tutorials/keras
##### Bayesian Deep Learning에 대해 공부 중...(2)
###### Edwith 강의 https://www.edwith.org/bayesiandeeplearning/joinLectures/14426
##### Algorithm
###### Programmers https://programmers.co.kr/

-----
### (keras) Text Classification
##### IMDB review data binary classification

IMDB data를 통해 영화 리뷰 내용이 영화를 긍정/부정으로 판단하고 있음을 분류하는 모델을 만들었다.  
아래는 오늘 새롭게 알게 된 keras의 기능들이다.
  
```python
# Data preprocessing
# For sequence data, add padding to post(or pre) position of the sequence with the value
train_data = keras.preprocessing.sequence.pad_sequences(train_data,
                                         value=word_index["<PAD>"],
                                         padding="post",
                                         maxlen=256)

test_data = keras.preprocessing.sequence.pad_sequences(test_data,
                                         value=word_index["<PAD>"],
                                         padding="post",
                                         maxlen=256)
```
  
```python
# Another way to build the network
model = keras.Sequential()
model.add(keras.layers.Embedding(vocab_size, 16, input_shape=(None,)))
model.add(keras.layers.GlobalAveragePooling1D())
model.add(keras.layers.Dense(16, activation=tf.nn.relu))
model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))
```
  
```python
# Print the summary of the network
# Output below
model.summary()
```
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 16)          160000    
_________________________________________________________________
global_average_pooling1d (Gl (None, 16)                0         
_________________________________________________________________
dense (Dense)                (None, 16)                272       
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 160,289
Trainable params: 160,289
Non-trainable params: 0
_________________________________________________________________
```
  
```python
# More parameters to train the model
# verbose: 0(silent), 1(progress bar), 2(one line per epoch)
# history usage below
history = model.fit(partial_x_train,
                   partial_y_train,
                   epochs=40,
                   batch_size=512,
                   validation_data=(x_val, y_val),
                   verbose=2)
```
  
```python
# history_dict contains the keys ['loss', 'acc', 'val_loss', 'val-acc']
history_dict = history.history
```


<br>
<br>

### (Bayesian Deep Learning) Measure Theory

σ-field(sigma field)란 무엇일까?
  
![](https://t1.daumcdn.net/cfile/tistory/99CE204F5B2F4C402C)
    
예를 통해 이해해보도록 하자. 100명의 사람들의 몸무게를 측정한다고 하자. 위에 나온 특징들을 번호별로 이해해보자.  

1. 1명의 몸무게를 잴 수 있다면 99명의 몸무게도 잴 수 있어야 한다.
2. 1명의 몸무게를 잴 수 있다면 (1+1)2명의 몸무게도 잴 수 있어야 한다. 마찬가지로 (1+2)3명, (1+3, 2+2)4명, ... 의 몸무게도 잴 수 있어야 한다.  

여기서 가장 대표적인 σ-field의 예로는 power set이 있을 것이다. 0명, 1명, 2명, ..., 100명의 몸무게를 모두 잰 부분 집합의 집합은 σ-field가 된다. 또는 짝수 명의 몸무게를 잰 부분 집합의 집합 역시 σ-field이다.  
이때 σ-field는 다음과 같은 특징들을 가진다.  

1. *Entire set is included.* Empty set이 포함되고 그 complimet가 포함되어야 하므로 Entire set 역시 포함된다. 
2. *either finite or uncountable, never denumerable 하다.*  finite의 경우 위에 예시로는 들었던 100(finite)명의 몸무게를 재는 상황이 있을 것이고, 만약 n is infinite하다면(denumerable, aleph null) 그 power set은 크기가 2<sup>aleph null</sup>이므로 uncountable 하다. 그러므로 σ-field는 *either finite or uncountable, never denumerable* 하다.
3. *If B and C are σ-field, B ∩ C is σ-field but B ∪ C is not.*  
  &nbsp; \- B = {{}, {a}, {b,c}, {a,b,c}} => σ-field  
  &nbsp; \- C = {{}, {a,b}, {c}, {a,b,c}} => σ-field  
  &nbsp; \- B ∩ C = {{}, {a,b,c}} => σ-field  
  &nbsp; \- B ∪ C = {{}, {a}, {c}, {a,b}, {b,c}, {a,b,c}} => not σ-field because there is no subset {a,c}  
  
σ-field가 정의된 이유는 다음과 같다고 볼 수 있겠다.  
  
**A σ-field is designed to define a measure**  
**If the element is not inside a σ-field, it cannot be measured**  
  
그리고 다음과 같은 **measurable space**를 정의할 수 있다.  
  
*A set U and a  σ-field of subsets of U form a **measurable space** (U, B).*
  
*measure*는 empty set에 대해 0이란는 값을 갖고, 겹치지 않는 set에 대하여 그 합이 보존된다는 특징을 갖는다. 즉, 겹치지 않는 2명과 3명의 몸무게를 쟀을 때 그 2명과 3명을 합친 5명의 몸무는 2명과 3명의 몸무게를 잰 것의 합과 같다는 얘기이다. 자연스럽게 U가 확률 집합이라면 U에 대한 *measure*값은 **1**이 될 것이다.

<br>
<br>

### (Algorithm) 힙(Heap) '더 맵게'

https://programmers.co.kr/learn/courses/30/lessons/42626?language=python3  
해당 문제를 풂에 있어 처음에는 단순히 list의 sort를 통해 문제를 해결하려 했는데, 효율성 테스트에서 실패하였다. 그래서 자료구조를 min heap으로 가져간 후 heap sort의 방식으로 문제를 해결하여 정확도 및 효율성 테스트를 모두 통과하였다.  
나의 정답 코드는 다음과 같다.

```python
import heapq

def solution(s, K):
    answer = 0
    # Heapify the list for using heap sort algorithm
    heapq.heapify(s)
    
    while s[0] < K:
        # If it's not possible return -1
        if len(s) == 1:
            return -1
        
        # Make the dish spicier
        heapq.heappush(s, heapq.heappop(s) + heapq.heappop(s)*2)
        
        answer += 1
        
    return answer
```

<br>

---------
## TO DO
